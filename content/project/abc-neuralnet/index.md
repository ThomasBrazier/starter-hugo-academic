---
title: "ABC with Bayesian Neural networks"
summary: "Bayesian Deep Learning and ABC for Population Genomics Inference."
abstract: ""
date: 2026-02-10T13:14:06.043Z
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
---
Modern population genomics inference increasingly relies on complex stochastic models for which likelihood functions are either analytically intractable or computationally prohibitive to evaluate. This challenge is particularly acute in population genetics, evolutionary biology, and systems biology, where both coalescent and forward-time simulators can generate data under sophisticated models, but the corresponding likelihood functions remain intractable.
Approximate Bayesian Computation (ABC) provides a likelihood-free framework for parameter inference in such settings. The fundamental principle of ABC relies on the intuition that simulated data sets with summary statistics close to those observed are likely to have been generated by similar parameter values.
Recent advances in deep learning offer promising solutions to preform likelihood-free parameter inference in a Bayesian framework. Neural networks can learn complex mappings between high-dimensional summary statistics and parameter spaces, effectively learning an implicit likelihood or posterior approximation.
The [abcneuralnet](thomasbrazier.github.io/abcneuralnet/) R package implements four state-of-the-art Bayesian deep learning approaches:
* Concrete Dropout: Provides rigorous uncertainty quantification through approximate variational inference, specifically a refinement of dropout as variational Bayesian approximation where the dropout rate is learned during inference
* Monte Carlo Dropout: A simpler dropout approach, which offers uncertainty estimation through stochastic forward passes, yet requiring careful tuning of the dropout rate hyper-parameter
* Deep Ensemble: A highly efficient ensemble approach delivering robust predictions through model averaging
* TabNet-ABC: Combines interpretable attention mechanisms with traditional ABC regression
Each method addresses different aspects of the ABC inference problem, with their own advantages and limitations, while maintaining compatibility with existing ABC workflows and providing rigorous uncertainty quantification essential for scientific inference.
